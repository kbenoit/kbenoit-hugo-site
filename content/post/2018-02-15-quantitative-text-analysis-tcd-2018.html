---
author: Ken
categories:
- Course-related
- Quantitative Methods
- Text Analysis
date: "2018-02-15T15:30:30Z"
id: 1460
title: Quantitative Text Analysis (TCD 2018)
url: /quantitative-text-analysis-tcd-2018/
output:
  blogdown::html_page:
    toc: true
---


<div id="TOC">
<ul>
<li><a href="#overview" id="toc-overview">Overview</a></li>
<li><a href="#objectives" id="toc-objectives">Objectives</a></li>
<li><a href="#detailed-course-schedule" id="toc-detailed-course-schedule">Detailed Course Schedule</a>
<ul>
<li><a href="#week-1-introduction-and-issues-in-quantitative-text-analysis" id="toc-week-1-introduction-and-issues-in-quantitative-text-analysis">Week 1: Introduction and issues in quantitative text analysis</a></li>
<li><a href="#week-2-quantitative-methods-for-comparing-texts" id="toc-week-2-quantitative-methods-for-comparing-texts">Week 2: Quantitative methods for comparing texts</a></li>
<li><a href="#week-3-automated-dictionary-based-approaches" id="toc-week-3-automated-dictionary-based-approaches">Week 3: Automated dictionary-based approaches</a></li>
<li><a href="#week-4-machine-learning-and-scaling-for-texts" id="toc-week-4-machine-learning-and-scaling-for-texts">Week 4: Machine learning and scaling for texts</a></li>
<li><a href="#week-5-scaling-models" id="toc-week-5-scaling-models">Week 5: Scaling models</a></li>
</ul></li>
<li><a href="#final-assignment" id="toc-final-assignment">Final Assignment</a></li>
<li><a href="#references" id="toc-references">References</a></li>
</ul>
</div>

<p><strong>When and where:</strong> 16 February, 23 February, 9 March, 16 March, 23 March 2018; Arts Building 3020.</p>
<p><strong>Instructor:</strong> Professor Kenneth Benoit, <a href="mailto:kbenoit@tcd.ie" class="email">kbenoit@tcd.ie</a>. Assignment marking by <a href="MULLERS@tcd.ie">Stefan Muüller</a>.</p>
<div id="overview" class="section level2">
<h2>Overview</h2>
<p>The course surveys methods for systematically extracting quantitative information from political text for social scientific purposes, starting with classical content analysis and dictionary-based methods, to classification methods, and state-of-the-art scaling methods and topic models for estimating quantities from text using statistical techniques. The course lays a theoretical foundation for text analysis but mainly takes a very practical and applied approach, so that students learn how to apply these methods in actual research. The common focus across all methods is that they can be reduced to a three-step process: first, identifying texts and units of texts for analysis; second, extracting from the texts quantitatively measured features - such as coded content categories, word counts, word types, dictionary counts, or parts of speech - and converting these into a quantitative matrix; and third, using quantitative or statistical methods to analyse this matrix in order to generate inferences about the texts or their authors. The course systematically covers these methods in a logical progression, with a practical, hands-on approach where each technique will be applied using appropriate software to real texts.</p>
</div>
<div id="objectives" class="section level2">
<h2>Objectives</h2>
<p>The course is also designed to cover many fundamental issues in quantitative text analysis such as inter-coder agreement, reliability, validation, accuracy, and precision. It focuses on methods of converting texts into quantitative matrixes of features, and then analysing those features using statistical methods. The course briefly covers the qualitative technique of human coding and an- notation but only for the purposes of creating a validation set for automated approaches. These automated approaches include dictionary construction and application, classification and machine learning, scaling models, and topic models. For each topic, we will systematically cover published applications and examples of these methods, from a variety of disciplinary and applied fields but focusing on political science. Lessons will consist of a mixture of theoretical grounding in content analysis approaches and techniques, with hands on analysis of real texts using content analytic and statistical software.</p>
</div>
<div id="detailed-course-schedule" class="section level2">
<h2>Detailed Course Schedule</h2>
<div id="week-1-introduction-and-issues-in-quantitative-text-analysis" class="section level3">
<h3><a href="/assets/courses/tcd2018qta/QTA_TCD_Day1.pdf">Week 1: Introduction and issues in quantitative text analysis</a></h3>
<p>This session will cover fundamentals, including the continuum from traditional
(non-computer assisted) content analysis to fully automated quantitative text
analysis. We will cover the conceptual foundations of content analysis and
quantitative content analysis, discuss the objectives, the approach to
knowledge, and the particular view of texts when performing quantitative
analysis. We will also discuss issues including where to obtain textual data;
formatting and working with text files; indexing and meta-data; units of
analysis; and definitions of features and measures commonly extracted
from texts, including stemming, and stop-words.</p>
<div id="required-reading" class="section level4">
<h4>Required Reading</h4>
<ul>
<li>Vignette and instructions at <a href="https://docs.quanteda.io" class="uri">https://docs.quanteda.io</a><br />
</li>
<li>Tutorials at <a href="https://tutorials.quanteda.io/" class="uri">https://tutorials.quanteda.io/</a><br />
</li>
<li>Grimmer and Stewart (2013)<br />
</li>
<li>Manning, Raghavan and Schütze (2008, 117–120)<br />
</li>
<li>Krippendorff (2013, Chs. 9–10)<br />
</li>
<li>Dunning (1993)</li>
</ul>
</div>
<div id="recommended-reading" class="section level4">
<h4>Recommended Reading</h4>
<ul>
<li>Krippendorff (2013, Ch. 1–2, 5, 7)<br />
</li>
<li>Wikipedia entry on Character encoding, <a href="http://en.wikipedia.org/wiki/Text_encoding" class="uri">http://en.wikipedia.org/wiki/Text_encoding</a><br />
</li>
<li>Browse the different text file formats at <a href="http://www.fileinfo.com/filetypes/text" class="uri">http://www.fileinfo.com/filetypes/text</a><br />
</li>
<li>Neuendorf (2002, Chs. 4–7)<br />
</li>
<li>Krippendorff (2013, Ch. 6)<br />
</li>
<li>Däubler et al. (2012)</li>
</ul>
</div>
<div id="resources" class="section level4">
<h4>Resources</h4>
<ul>
<li><a href="/assets/courses/tcd2018qta/QTA_TCD_Day1.pdf">Week 1 slides</a><br />
</li>
<li><a href="/assets/courses/tcd2018qta/getting_started.html">Getting Started with quanteda and R</a> and the <a href="/assets/courses/tcd2018qta/getting_started.Rmd"><code>.Rmd</code> source</a>, which you should save and try to knit</li>
<li><a href="/assets/courses/tcd2018qta/assignment1_LASTNAME_FIRSTNAME.html">Assignment 1: Working with Texts in quanteda</a> and <a href="https://cdn.rawgit.com/kbenoit/kbenoit.github.io/4bf16046/assets/courses/tcd2018qta/assignment1_LASTNAME_FIRSTNAME.Rmd"><code>.Rmd</code> source</a></li>
</ul>
</div>
</div>
<div id="week-2-quantitative-methods-for-comparing-texts" class="section level3">
<h3><a href="/assets/courses/tcd2018qta/QTA_TCD_Day2.pdf">Week 2: Quantitative methods for comparing texts</a></h3>
<p>Here we focus on quantitative methods for describing texts, focusing on summary measures that highlight particular characteristics of documents and allowing these to be compared. These meth- ods include characterizing texts through concordances, co-occurrences, and keywords in context; complexity and readability measures; and an in-depth discussion of text types, tokens, and equiv- alencies. We will also discuss weighting strategies for features, such as tf-idf. The emphasis will be on comparing texts, through concordances and keyword identification, dissimilarity measures, association models, and vector-space models.</p>
<div id="required-reading-1" class="section level4">
<h4>Required Reading</h4>
<ul>
<li>Krippendorff (2013, Ch. 10)<br />
</li>
<li>Lowe et al. (2011)<br />
</li>
<li>Manning, Raghavan and Schütze (2008, Section 6.3)</li>
</ul>
</div>
<div id="recommended-reading-1" class="section level4">
<h4>Recommended Reading</h4>
<ul>
<li>Seale, Ziebland and Charteris-Black (2006)</li>
</ul>
</div>
<div id="resources-1" class="section level4">
<h4>Resources</h4>
<ul>
<li><a href="/assets/courses/tcd2018qta/QTA_TCD_Day2.pdf">Week 2 slides</a></li>
<li><a href="/assets/courses/tcd2018qta/assignment2_LASTNAME_FIRSTNAME.html">Exercise 2: Describing and comparing texts and their features</a> and <a href="https://cdn.rawgit.com/kbenoit/kbenoit.github.io/73accef5/assets/courses/tcd2018qta/assignment2_LASTNAME_FIRSTNAME.Rmd"><code>.Rmd</code> source</a></li>
</ul>
</div>
</div>
<div id="week-3-automated-dictionary-based-approaches" class="section level3">
<h3><a href="/assets/courses/tcd2018qta/QTA_TCD_Day3.pdf">Week 3: Automated dictionary-based approaches</a></h3>
<p>Automatic dictionary-based methods involve association of pre-defined word lists with particular quantitative values assigned by the researcher for some characteristic of interest. This topic covers the design model behind dictionary construction, including guidelines for testing and refining dic- tionaries. Hand-on work will cover commonly used dictionaries such as LIWC, RID, and the Harvard IV-4, with applications. We will also review a variety of text pre-processing issues and textual data concepts such as word types, tokens, and equivalencies, including word stemming and trimming of words based on term and/or document frequency.</p>
<div id="required-reading-2" class="section level4">
<h4>Required Reading</h4>
<ul>
<li>Neuendorf (2002, Ch. 6)<br />
</li>
<li>Laver and Garry (2000)<br />
</li>
<li>Rooduijn and Pauwels (2011)</li>
</ul>
</div>
<div id="recommended-reading-2" class="section level4">
<h4>Recommended Reading</h4>
<ul>
<li>Pennebaker and Chung (2008)<br />
</li>
<li>Tausczik and Pennebaker (2010)<br />
</li>
<li>Loughran and McDonald (2011)</li>
</ul>
</div>
<div id="resources-2" class="section level4">
<h4>Resources</h4>
<ul>
<li><a href="/assets/courses/tcd2018qta/QTA_TCD_Day3.pdf">Week 3 slides</a><br />
</li>
<li><a href="/assets/courses/tcd2018qta/assignment3_LASTNAME_FIRSTNAME.html">Exercise 3: Applying, modifying, and creating dictionaries for the analysis of political texts.</a> and <a href="https://cdn.rawgit.com/kbenoit/kbenoit.github.io/3ef69b09/assets/courses/tcd2018qta/assignment3_LASTNAME_FIRSTNAME.Rmd"><code>.Rmd</code> source</a></li>
</ul>
</div>
</div>
<div id="week-4-machine-learning-and-scaling-for-texts" class="section level3">
<h3><a href="/assets/courses/tcd2018qta/QTA_TCD_Day4.pdf">Week 4: Machine learning and scaling for texts</a></h3>
<p>Classification methods permit the automatic classification of texts in a test set following machine learning from a training set. We will introduce machine learning methods for classifying documents, including one of the most popular classifiers, the Naive Bayes model. The topic also introduces validation and reporting methods for classifiers and discusses where these methods are applicable. Building on the Naive Bayes classifier, we introduce the “Wordscores” method of Laver, Benoit and Garry (2003) for scaling latent traits, and show the link between classification and scaling. We also cover applications of penalized regression to score and scale texts.</p>
<div id="resources-3" class="section level4">
<h4>Resources</h4>
<ul>
<li><a href="/assets/courses/tcd2018qta/QTA_TCD_Day4.pdf">Week 4 slides</a><br />
</li>
<li><a href="/assets/courses/tcd2018qta/assignment4_LASTNAME_FIRSTNAME.html">Exercise 4: Machine learning and scaling for texts.</a> and <a href="https://cdn.rawgit.com/kbenoit/kbenoit.github.io/5fb4ba46/assets/courses/tcd2018qta/assignment4_LASTNAME_FIRSTNAME.Rmd"><code>.Rmd</code> source</a></li>
</ul>
</div>
<div id="required-reading-3" class="section level4">
<h4>Required Reading</h4>
<ul>
<li>Manning, Raghavan and Schütze (2008, Ch. 13)<br />
</li>
<li>Lantz (2013, Ch. 3–4)</li>
</ul>
</div>
<div id="recommended-reading-3" class="section level4">
<h4>Recommended Reading</h4>
<ul>
<li>Lantz (2013, Ch. 10)<br />
</li>
<li>Statsoft, “Naive Bayes Classifier Introductory Overview,” <a href="http://www.statsoft.com/textbook/naive-bayes-classifier/" class="uri">http://www.statsoft.com/textbook/naive-bayes-classifier/</a>.<br />
</li>
<li>An online article by Paul Graham on classifying spam e-mail. <a href="http://www.paulgraham" class="uri">http://www.paulgraham</a>. com/spam.html.<br />
</li>
<li>Bionicspirit.com, 9 Feb 2012, “How to Build a Naive Bayes Classifier,” <a href="http://bionicspirit" class="uri">http://bionicspirit</a>. com/blog/2012/02/09/howto-build-naive-bayes-classifier.html.<br />
</li>
<li>Yu, Kaufmann and Diermeier (2008)<br />
</li>
<li>Zumel and Mount (2014, Ch. 5–6)<br />
</li>
<li>Benoit and Nulty (2013)<br />
</li>
<li>Martin and Vanberg (2007)<br />
</li>
<li>Benoit and Laver (2008)<br />
</li>
<li>Lowe (2008)</li>
</ul>
</div>
</div>
<div id="week-5-scaling-models" class="section level3">
<h3><a href="/assets/courses/tcd2018qta/QTA_TCD_Day5.pdf">Week 5: Scaling models</a></h3>
<p>Building on the Naive Bayes classifier, we introduce the “Wordscores” method of Laver, Benoit and Garry (2003) for scaling latent traits, and show the link between classification and scaling. We also cover the unsupervised “Wordfish” scaling method of Slapin and Proksch (2008).</p>
<div id="required-reading-4" class="section level4">
<h4>Required Reading</h4>
<ul>
<li>Evans et al. (2007)<br />
</li>
<li>Laver, Benoit and Garry (2003)<br />
</li>
<li>Slapin and Proksch (2008)</li>
</ul>
</div>
<div id="recommended-reading-4" class="section level4">
<h4>Recommended Reading</h4>
<ul>
<li>Beil, Ester and Xu (2002)</li>
<li>Chang et al. (2009)</li>
<li>Gilardi et al. (2017)</li>
<li>Lucas et al (2015)</li>
<li>Manning, Raghavan and Schütze (2008, Ch. 16–17)</li>
<li>James et al. (2013, Ch. 10.3)</li>
<li>Zumel and Mount (2014, Ch. 8)</li>
</ul>
</div>
<div id="resources-4" class="section level4">
<h4>Resources</h4>
<ul>
<li><a href="/assets/courses/tcd2018qta/exercise5.html">Exercise 5: Classifying legal documents and legislative speeches.</a></li>
</ul>
</div>
</div>
</div>
<div id="final-assignment" class="section level2">
<h2>Final Assignment</h2>
<div id="project-guidelines" class="section level4">
<h4>Project Guidelines</h4>
<p>The final project is a written analysis of approximately 4,000-5,000 words. The project replaces a final exam, and is designed to give you a chance to analyze a set of texts that you have chosen, reflecting (hopefully) your own research interests. This can be, and probably makes the most sense to be, textual data from something you are already studying. Which texts you choose, what question you investigate, and how you analyze the texts is your choice, but you must justify the choice.</p>
</div>
<div id="content" class="section level4">
<h4>Content</h4>
<p>Your content should include the following:</p>
<ol style="list-style-type: decimal">
<li>A cover sheet including the title and your name.<br />
</li>
<li>An abstract page, with an abstract of no more than 200 words.<br />
</li>
<li>Introduction. An expanded version of your abstract, which introduces the question, states the rationale for trying to answer it, briefly describes your corpus, identifies the methods you apply to the texts, and summarizes the findings.</li>
<li>Motivation. Why have you chosen to analyze this topic? Is there a compelling social reason? Does it contribute to scholarship? This can include a “literature review” (but don’t overdo it).</li>
<li>Description of your corpus. You are free to choose any corpus you wish, of any size, although you must include a justification for the choice of texts, and acknowledge the source. You will need to document any format conversions or pre-processing steps you have applied to the texts prior to analysis. You should also present some basic summary statistics about the texts, prior to analysis.</li>
<li>Description of your methods. What techniques will you apply to analyze the texts? Is there a precedent (in previous scholarly literature) for applying such methods to texts similar to yours? Defend why the application of the methods is appropriate.</li>
<li>Results. Apply the methods, present the findings. Be sure to be explicit about any steps taken.</li>
<li>Conclusions. What conclusions on the question can we draw from the results?</li>
</ol>
</div>
<div id="formatting" class="section level4">
<h4>Formatting</h4>
<p>There is no rigid set of guidelines, but you should use a Chicago manual of style compatible referencing system (parenthetical references rather than footnotes). Tables should be formatted rather than consisting of pasted output from a statistical package. Think of trying to look (roughly) as if you were formatting a journal article.</p>
</div>
<div id="deadline" class="section level4">
<h4>Deadline</h4>
<p>30 April 2018, 5pm, by email to <a href="mailto:kbenoit@tcd.ie">kbenoit@tcd.ie</a>.</p>
</div>
</div>
<div id="references" class="section level2">
<h2>References</h2>
<p>Barberá, Pablo. 2015. “Birds of the Same Feather Tweet Together: Bayesian Ideal Point Estimation Using Twitter Data.” <em>Political Analysis</em> 23(1):76–91. doi: <a href="https://doi.org/10.1093/pan/mpu011"><code>10.1093/pan/mpu011</code></a>.</p>
<p>Beauchamp, N. 2017. “<a href="http://onlinelibrary.wiley.com/doi/10.1111/ajps.12274/full">Predicting and Interpolating State‐Level Polls Using Twitter Textual Data.</a>” <em>American Journal of Political Science</em> 61(2), 490-503.</p>
<p>Beil, F, M Ester and X Xu. 2002. Frequent term-based text clustering. In <em>Eighth ACM SIGKDD international conference on Knowledge discovery and data mining</em>. pp. 436–442.</p>
<p>Benoit, K. and M. Laver. 2008. “Compared to What? A Comment on ‘A Robust Transformation
Procedure for Interpreting Political Text’ by Martin and Vanberg.” <em>Political Analysis</em> 16(1):101–111. doi: <a href="https://doi.org/10.1093/pan/mpm020"><code>10.1093/pan/mpm020</code></a>.</p>
<p>Benoit, Kenneth and Paul Nulty. 2013. “Classification Methods for Scaling Latent Political Traits.” Presented at the Annual Meeting of the Midwest Political Science Association, April 11–14, Chicago.</p>
<p>Blei, David M. 2012. “Probabilistic topic models.” <em>Communications of the ACM</em> 55(4):77. doi: <a href="https://doi.org/10.1145/2133806.2133826"><code>10.1145/2133806.2133826</code></a>.</p>
<p>Blei, D.M., A.Y. Ng and M.I. Jordan. 2003. “Latent dirichlet allocation.” <em>The Journal of Machine Learning Research</em> 3:993–1022.</p>
<p>Chang, J., J. Boyd-Graber, S. Gerrish, C. Wang and D. Blei. 2009. Reading tea leaves: How humans interpret topic models. In <em>Neural Information Processing Systems.</em></p>
<p>Choi, Seung-Seok, Sung-Hyuk Cha and Charles C. Tappert. 2010. “A Survey of Binary Similarity and Distance Measures.” <em>Journal of Systemics, Cybernetics and Informatics</em> 8(1):43–48.</p>
<p>Clinton, J., S. Jackman and D. Rivers. 2004. “The statistical analysis of roll call voting: A unified approach.” <em>American Journal of Political Science</em> 98(2):355–370. doi: <a href="https://doi.org/10.1017/s0003055404001194"><code>10.1017/s0003055404001194</code></a>.</p>
<p>Corley, Courtney and Rada Mihalcea. 2005. Measuring the semantic similarity of texts. In <em>Proceedings of the ACL Workshop on Empirical Modeling of Semantic Equivalence and Entailment - EMSEE ’05</em>.</p>
<p>Däubler, Thomas, Kenneth Benoit, Slava Mikhaylov and Michael Laver. 2012. “Natural Sentences as Valid Units for Coded Political Texts.” <em>British Journal of Political Science</em> 42(4):937–951. doi: <a href="https://doi.org/10.1017/S0007123412000105"><code>10.1017/S0007123412000105</code></a>.</p>
<p>DuBay, William. 2004. The Principles of Readability. Costa Mesa, California. <a href="http://www.impact-information.com/impactinfo/readability02.pdf" class="uri">http://www.impact-information.com/impactinfo/readability02.pdf</a>.</p>
<p>Dunning, Ted. 1993. “Accurate methods for the statistics of surprise and coincidence.” <em>Computational Linguistics</em> 19:61–74.</p>
<p>Evans, Michael, Wayne McIntosh, Jimmy Lin and Cynthia Cates. 2007. “Recounting the Courts?
Applying Automated Content Analysis to Enhance Empirical Legal Research.” <em>Journal of Empirical Legal Studies</em> 4(4):1007–1039.</p>
<p>Gilardi, F., Shipan, C. R., &amp; Wueest, B. 2017. “<a href="https://www.fabriziogilardi.org/resources/papers/policy-diffusion-issue-definition.pdf">Policy Diffusion: The Issue-Definition Stage.</a>” Working paper, University of Zurich.</p>
<p>Ginsberg, Jeremy, Matthew H Mohebbi, Rajan S Patel, Lynnette Brammer, Mark S Smolinski and Larry Brilliant. 2008. “Detecting influenza epidemics using search engine query data.” <em>Nature</em> 457(7232):1012–1014.</p>
<p>Grimmer, Justin and Brandon M. Stewart. 2013. “Text as Data: The Promise and Pitfalls of Automatic Content Analysis Methods for Political Texts.” <em>Political Analysis</em> 21(3):267–297. doi: <a href="https://doi.org/10.1093/pan/mps028"><code>10.1093/pan/mps028</code></a>.</p>
<p>Gurciullo, S., &amp; Mikhaylov, S. J. 2016. “<a href="http://www.smikhaylov.net/wp-content/uploads/2017/04/UNembeddings.pdf">Detecting Policy Preferences and Dynamics in the UN General Debate with Neural Word Embeddings</a>”. Working paper, University College London.</p>
<p>James, Gareth, Daniela Witten, Trevor Hastie and Robert Tibshirani. 2013. <em>An Introduction to Statistical Learning with Applications in R</em>. Springer Science &amp; Business Media.</p>
<p>Jürgens, Pascal and Andreas Jungherr. 2016. “A Tutorial for Using Twitter Data in the Social Sciences: Data Collection, Preparation, and Analysis.”</p>
<p>Klašnja, M., Barberá, P., Beauchamp, N., Nagler, J., &amp; Tucker, J. 2016. “<a href="http://www.oxfordhandbooks.com/view/10.1093/oxfordhb/9780190213299.001.0001/oxfordhb-9780190213299-e-3">Measuring public opinion with social media data.</a>” In The Oxford Handbook of Polling and Survey Methods.</p>
<p>Krippendorff, Klaus. 2013. <em>Content Analysis: An Introduction to Its Methodology</em>. 3rd ed. Thousand Oaks, CA: Sage.</p>
<p>Lampos, Vasileios, Daniel Preotiuc-Pietro and Trevor Cohn. 2013. A user-centric model of voting intention from Social Media. In <em>Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL)</em>.</p>
<p>Lantz, Brett. 2013. <em>Machine Learning with R.</em> Packt Publishing Ltd.</p>
<p>Laver, M. and J. Garry. 2000. “Estimating policy positions from political texts.” <em>American Journal of Political Science</em> 44(3):619–634. doi: <a href="https://doi.org/10.2307/2669268"><code>10.2307/2669268</code></a>.</p>
<p>Laver, Michael, Kenneth Benoit and John Garry. 2003. “Estimating the policy positions of political actors using words as data.” <em>American Political Science Review</em> 97(2):311–331. doi: <a href="https://doi.org/10.1017/S0003055403000698"><code>10.1017/S0003055403000698</code></a>.</p>
<p>Loughran, Tim and Bill McDonald. 2011. “When Is a Liability Not a Liability? Textual Analysis, Dictionaries, and 10-Ks.” <em>The Journal of Finance</em> 66(1):35–65.</p>
<p>Lowe, W. 2008. “Understanding Wordscores.” <em>Political Analysis</em> 16(4):356–371. doi: <a href="https://doi.org/10.1093/pan/mpn004"><code>10.1093/pan/mpn004</code></a>.</p>
<p>Lowe, William and Kenneth Benoit. 2013. “Validating Estimates of Latent Traits From Textual Data Using Human Judgment as a Benchmark.” <em>Political Analysis</em> 21(3):298–313. doi: <a href="https://doi.org/10.1093/pan/mpt002"><code>10.1093/pan/mpt002</code></a>.</p>
<p>Lowe, William, Kenneth Benoit, Slava Mikhaylov and Michael Laver. 2011. “Scaling Policy Preferences From Coded Political Texts.” <em>Legislative Studies Quarterly</em> 26(1):123–155. doi: <a href="https://doi.org/10.1111/j.1939-9162.2010.00006.x"><code>10.1111/j.1939-9162.2010.00006.x</code></a>.</p>
<p>Lucas, C., Nielsen, R. A., Roberts, M. E., Stewart, B. M., Storer, A., &amp; Tingley, D. 2015. “<a href="http://scholar.princeton.edu/sites/default/files/bstewart/files/comparativepoliticstext.pdf">Computer-assisted text analysis for comparative politics.</a>” Political Analysis, 23(2), 254-277.</p>
<p>Manning, C. D., P. Raghavan and H. Schütze. 2008. <em>Introduction to Information Retrieval</em>. Cambridge University Press.</p>
<p>Martin, L. W. and G. Vanberg. 2007. “A robust transformation procedure for interpreting political text.” <em>Political Analysis</em> 16(1):93–100. doi: <a href="https://doi.org/10.1093/pan/mpm010"><code>10.1093/pan/mpm010</code></a>.</p>
<p>Metaxas, Panagiotis T., Eni Mustafaraj and Daniel Gayo-Avello. 2011. How (not) to predict elections. In <em>Privacy, security, risk and trust (PASSAT), 2011 IEEE third international conference on social computing (SocialCom)</em>.</p>
<p>Mikolov, T., Chen, K., Corrado, G., &amp; Dean, J. 2013. “Efficient estimation of word representations in vector space.” <a href="https://arxiv.org/pdf/1301.3781.pdf">arXiv preprint arXiv:1301.3781.</a></p>
<p>Neuendorf, K. A. 2002. <em>The Content Analysis Guidebook</em>. Thousand Oaks CA: Sage.</p>
<p>Pennebaker, J. W. and C. K. Chung. 2008. Computerized text analysis of al-Qaeda transcripts. In <em>The Content Analysis Reader</em>, ed. K. Krippendorf and M. A. Bock. Thousand Oaks, CA: Sage.</p>
<p>Roberts, Margaret E, Brandon M Stewart, Dustin Tingley, Christopher Lucas, Jetson Leder-Luis, Shana Kushner Gadarian, Bethany Albertson and David G Rand. 2014. “Structural Topic Models for Open-Ended Survey Responses.” <em>American Journal of Political Science</em> 58(4):1064–1082. doi: <a href="https://doi.org/10.1080/01621459.2016.1141684"><code>10.1080/01621459.2016.1141684</code></a>.</p>
<p>Rooduijn, Matthijs and Teun Pauwels. 2011. “Measuring Populism: Comparing Two Methods of
Content Analysis.” <em>West European Politics</em> 34(6):1272–1283.</p>
<p>Ruths, D., &amp; Pfeffer, J. 2014. “<a href="http://science.sciencemag.org/content/346/6213/1063.full">Social media for large studies of behavior.</a>” Science, 346(6213), 1063-1064.</p>
<p>Seale, Clive, Sue Ziebland and Jonathan Charteris-Black. 2006. “Gender, cancer experience and internet use: A comparative keyword analysis of interviews and online cancer support groups.” <em>Social Science &amp; Medicine</em> 62(10):2577–2590.</p>
<p>Slapin, Jonathan B. and Sven-Oliver Proksch. 2008. “A Scaling Model for Estimating Time-Series Party Positions from Texts.” <em>American Journal of Political Science</em> 52(3):705–722. doi: <a href="10.1111/j.1540-5907.2008.00338.x"><code>10.1111/j.1540-5907.2008.00338.x</code></a>.</p>
<p>Steinert-Threlkeld, Z. 2018. “<a href="https://www.cambridge.org/core/elements/twitter-as-data/27B3DE20C22E12E162BFB173C5EB2592">Twitter as Data.</a>” Cambridge University Press.</p>
<p>Tausczik, Y R and James W Pennebaker. 2010. “The Psychological Meaning of Words: LIWC and
Computerized Text Analysis Methods.” <em>Journal of Language and Social Psychology</em> 29(1):24–54.</p>
<p>Young, L., and Soroka, S. 2012. “<a href="http://www.tandfonline.com/doi/abs/10.1080/10584609.2012.671234">Affective news: The automated coding of sentiment in political texts.</a>” <em>Political Communication</em> 29(2), 205-231.</p>
<p>Yu, B., S. Kaufmann and D. Diermeier. 2008. “Classifying Party Affiliation from Political Speech.” <em>Journal of Information Technology and Politics</em> 5(1):33–48.</p>
<p>Zumel, Nina and John Mount. 2014. <em>Practical Data Science with R</em>. Manning Publications.</p>
</div>
